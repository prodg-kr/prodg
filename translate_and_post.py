#!/usr/bin/env python3
"""
pronews.jp ìë™ ë²ˆì—­ ë° ì›Œë“œí”„ë ˆìŠ¤ ê²Œì‹œ ì‹œìŠ¤í…œ
- ì†ŒìŠ¤: jp.pronews.com/feed
- ë²ˆì—­: Google Translate (ì¼ë³¸ì–´ â†’ í•œêµ­ì–´)
- ê²Œì‹œ: prodg.kr WordPress
- ê¸°ëŠ¥: ì „ì²´ ë³¸ë¬¸ ìŠ¤í¬ë˜í•‘, ì´ë¯¸ì§€ ë³¸ë¬¸ ì‚½ì…
"""

import os
import sys
import requests
import feedparser
from datetime import datetime, timedelta
from pathlib import Path
import json
import time
from urllib.parse import urlparse, urljoin
from googletrans import Translator
import html2text
from bs4 import BeautifulSoup

# ==========================================
# ì„¤ì • (Settings)
# ==========================================
WORDPRESS_URL = "https://prodg.kr"
WORDPRESS_USER = os.environ.get("WP_USER")
WORDPRESS_APP_PASSWORD = os.environ.get("WP_APP_PASSWORD")
PRONEWS_RSS = "https://jp.pronews.com/feed"
POSTED_ARTICLES_FILE = "posted_articles.json"

# ì¤‘ë³µ ê²Œì‹œ ë°©ì§€ (Falseë¡œ ì„¤ì •í•˜ë©´ ì´ë¯¸ ì˜¬ë¦° ê¸€ì€ ê±´ë„ˆëœ€)
FORCE_UPDATE = False

class NewsTranslator:
    def __init__(self):
        self.translator = Translator()
        self.wordpress_api = f"{WORDPRESS_URL}/wp-json/wp/v2"
        self.posted_articles = self.load_posted_articles()
        
    def load_posted_articles(self):
        """ì´ë¯¸ ê²Œì‹œëœ ê¸°ì‚¬ ëª©ë¡ ë¡œë“œ"""
        if Path(POSTED_ARTICLES_FILE).exists():
            with open(POSTED_ARTICLES_FILE, 'r') as f:
                try:
                    return json.load(f)
                except:
                    return []
        return []
        
    def save_posted_articles(self):
        """ê²Œì‹œëœ ê¸°ì‚¬ ëª©ë¡ ì €ì¥"""
        with open(POSTED_ARTICLES_FILE, 'w') as f:
            json.dump(self.posted_articles, f, indent=2)
        
    def fetch_rss_feed(self):
        """RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸°"""
        print(f"ğŸ“¡ RSS í”¼ë“œ í™•ì¸ ì¤‘: {PRONEWS_RSS}")
        feed = feedparser.parse(PRONEWS_RSS)
        
        # 24ì‹œê°„ ì´ë‚´ ê¸°ì‚¬ë§Œ
        limit_date = datetime.now() - timedelta(days=1)
        recent_articles = []
        
        print(f"ğŸ” ì´ {len(feed.entries)}ê°œì˜ í”¼ë“œ í•­ëª© ê²€ìƒ‰ ì‹œì‘...")

        for entry in feed.entries[:20]:  # ìµœì‹  20ê°œ ì²´í¬
            # ì¤‘ë³µ ì²´í¬
            if not FORCE_UPDATE and entry.link in self.posted_articles:
                print(f"  â­ï¸  Pass (ì´ë¯¸ ê²Œì‹œë¨): {entry.title}")
                continue
                
            try:
                article_date = datetime(*entry.published_parsed[:6])
            except:
                article_date = datetime.now()
                
            if article_date > limit_date:
                recent_articles.append({
                    'title': entry.title,
                    'link': entry.link,
                    'date': article_date
                })
        
        print(f"âœ… ì²˜ë¦¬í•  ìƒˆ ê¸°ì‚¬: {len(recent_articles)}ê°œ")
        return recent_articles
        
    def fetch_full_content(self, url):
        """
        BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ê¸°ì‚¬ ë³¸ë¬¸ ì „ì²´ ìŠ¤í¬ë˜í•‘
        """
        try:
            print(f"ğŸ“„ ê¸°ì‚¬ ì›ë¬¸ ìŠ¤í¬ë˜í•‘ ì¤‘: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'lxml')
            
            # pronews.comì˜ ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
            # ì¼ë°˜ì ì¸ ì›Œë“œí”„ë ˆìŠ¤ êµ¬ì¡°: entry-content, post-content, article-content ë“±
            content_div = soup.find('div', class_='entry-content')
            if not content_div:
                content_div = soup.find('div', class_='post-content')
            if not content_div:
                content_div = soup.find('div', class_='article-content')
            if not content_div:
                content_div = soup.find('article')
                
            if not content_div:
                print("âš ï¸ ë³¸ë¬¸ ì˜ì—­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None

            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼, ê´‘ê³  ë“±)
            for tag in content_div(['script', 'style', 'iframe', 'noscript', 'form', 'nav']):
                tag.decompose()
            
            # ê´‘ê³  í´ë˜ìŠ¤ ì œê±°
            for ad_class in ['ad', 'advertisement', 'banner', 'sidebar']:
                for elem in content_div.find_all(class_=lambda x: x and ad_class in x.lower()):
                    elem.decompose()
                
            # HTML ë¬¸ìì—´ ë°˜í™˜
            return str(content_div)
            
        except Exception as e:
            print(f"âš ï¸ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return None

    def translate_text(self, text):
        """ë²ˆì—­ í•¨ìˆ˜ (ê¸´ í…ìŠ¤íŠ¸ ìë™ ë¶„í•  ì²˜ë¦¬)"""
        if not text: 
            return ""
        
        try:
            # HTMLì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            h = html2text.HTML2Text()
            h.ignore_links = False
            h.ignore_images = True  # ì´ë¯¸ì§€ëŠ” ë³„ë„ ì²˜ë¦¬
            h.body_width = 0  # ì¤„ë°”ê¿ˆ ë°©ì§€
            plain_text = h.handle(text)
            
            # ë„ˆë¬´ ê¸¸ë©´ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ë²ˆì—­ (Google API ì œí•œ ëŒ€ë¹„)
            max_chunk_size = 4000
            if len(plain_text) > max_chunk_size:
                print(f"   ğŸ“ ê¸´ í…ìŠ¤íŠ¸ ê°ì§€ ({len(plain_text)}ì) - ë¶„í•  ë²ˆì—­ ì‹œì‘")
                chunks = [plain_text[i:i+max_chunk_size] for i in range(0, len(plain_text), max_chunk_size)]
                translated_parts = []
                
                for i, chunk in enumerate(chunks, 1):
                    print(f"   ğŸ”„ ì²­í¬ {i}/{len(chunks)} ë²ˆì—­ ì¤‘...")
                    res = self.translator.translate(chunk, src='ja', dest='ko')
                    translated_parts.append(res.text)
                    time.sleep(1.5)  # API ì œí•œ ë°©ì§€
                    
                return "\n\n".join(translated_parts)
            else:
                result = self.translator.translate(plain_text, src='ja', dest='ko')
                time.sleep(0.8)
                return result.text
                
        except Exception as e:
            print(f"âš ï¸ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return text  # ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜

    def download_image(self, url):
        """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        if not url: 
            return None
        try:
            print(f"ğŸ–¼ï¸  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {url}")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            res = requests.get(url, headers=headers, timeout=15)
            res.raise_for_status()
            
            # íŒŒì¼ëª… ì²˜ë¦¬
            filename = os.path.basename(urlparse(url).path)
            if not filename or len(filename) > 100:
                filename = f"image_{int(time.time())}.jpg"
            
            # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°
            if '?' in filename:
                filename = filename.split('?')[0]
                
            path = Path(f"/tmp/{filename}")
            with open(path, 'wb') as f:
                f.write(res.content)
            
            print(f"   âœ… ì €ì¥ ì™„ë£Œ: {path.name}")
            return path
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì—ëŸ¬: {e}")
        return None

    def upload_media(self, image_path):
        """ì›Œë“œí”„ë ˆìŠ¤ ë¯¸ë””ì–´ ì—…ë¡œë“œ"""
        if not image_path or not image_path.exists(): 
            return None
        try:
            url = f"{self.wordpress_api}/media"
            headers = {
                'Content-Disposition': f'attachment; filename={image_path.name}'
            }
            with open(image_path, 'rb') as img:
                files = {'file': (image_path.name, img, 'image/jpeg')}
                res = requests.post(
                    url,
                    auth=(WORDPRESS_USER, WORDPRESS_APP_PASSWORD),
                    headers=headers,
                    files=files
                )
                res.raise_for_status()
                media_data = res.json()
                print(f"   âœ… ì—…ë¡œë“œ ì™„ë£Œ: ID {media_data['id']}")
                return media_data  # {id, source_url, ...}
                
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            if hasattr(e, 'response'):
                print(f"   ìƒì„¸: {e.response.text[:200]}")
        return None

    def get_main_image_url(self, link):
        """Open Graph ë“±ì„ í†µí•´ ëŒ€í‘œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
        try:
            headers = {'User-Agent': 'Mozilla/5.0'}
            res = requests.get(link, headers=headers, timeout=10)
            soup = BeautifulSoup(res.text, 'lxml')
            
            # 1. Open Graph ì´ë¯¸ì§€
            og_img = soup.find('meta', property='og:image')
            if og_img and og_img.get('content'):
                img_url = og_img['content']
                print(f"   ğŸ“¸ OG ì´ë¯¸ì§€ ë°œê²¬")
                return img_url
            
            # 2. Twitter Card ì´ë¯¸ì§€
            tw_img = soup.find('meta', attrs={'name': 'twitter:image'})
            if tw_img and tw_img.get('content'):
                img_url = tw_img['content']
                print(f"   ğŸ“¸ Twitter Card ì´ë¯¸ì§€ ë°œê²¬")
                return img_url
            
            # 3. ë³¸ë¬¸ ì²« ì´ë¯¸ì§€
            content = soup.find('div', class_='entry-content')
            if content:
                img = content.find('img')
                if img and img.get('src'):
                    img_url = img['src']
                    # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ
                    if not img_url.startswith('http'):
                        img_url = urljoin(link, img_url)
                    print(f"   ğŸ“¸ ë³¸ë¬¸ ì´ë¯¸ì§€ ë°œê²¬")
                    return img_url
            
        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return None

    def post_to_wordpress(self, title, content, featured_media_id):
        """ì›Œë“œí”„ë ˆìŠ¤ í¬ìŠ¤íŠ¸ ìƒì„±"""
        post_data = {
            'title': title,
            'content': content,
            'status': 'publish',
            'featured_media': featured_media_id if featured_media_id else 0
        }
        
        try:
            res = requests.post(
                f"{self.wordpress_api}/posts",
                auth=(WORDPRESS_USER, WORDPRESS_APP_PASSWORD),
                json=post_data
            )
            res.raise_for_status()
            post_info = res.json()
            print(f"âœ¨ ê²Œì‹œ ì„±ê³µ! ë§í¬: {post_info['link']}")
            return True
            
        except Exception as e:
            print(f"âŒ ê²Œì‹œ ì‹¤íŒ¨: {e}")
            if hasattr(e, 'response'):
                print(f"   ìƒì„¸: {e.response.text[:300]}")
            return False

    def process_article(self, article):
        """ê¸°ì‚¬ í•˜ë‚˜ ì²˜ë¦¬: ìŠ¤í¬ë˜í•‘ â†’ ë²ˆì—­ â†’ ì´ë¯¸ì§€ â†’ ê²Œì‹œ"""
        print(f"\n{'='*70}")
        print(f"ğŸ“° ì²˜ë¦¬ ì‹œì‘: {article['title']}")
        print(f"{'='*70}")
        
        # 1. ë³¸ë¬¸ ì „ì²´ ê°€ì ¸ì˜¤ê¸°
        raw_html = self.fetch_full_content(article['link'])
        if not raw_html:
            print("   âš ï¸  ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í•´ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
            
        # 2. ë²ˆì—­ (ì œëª© ë° ë³¸ë¬¸)
        print(f"ğŸ”„ ì œëª© ë²ˆì—­ ì¤‘...")
        title_ko = self.translate_text(article['title'])
        print(f"   âœ… \"{title_ko}\"")
        
        print(f"ğŸ”„ ë³¸ë¬¸ ë²ˆì—­ ì¤‘...")
        content_ko = self.translate_text(raw_html)
        print(f"   âœ… ë³¸ë¬¸ ë²ˆì—­ ì™„ë£Œ ({len(content_ko)}ì)")
        
        # 3. ì´ë¯¸ì§€ ì²˜ë¦¬
        print(f"ğŸ” ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
        img_url = self.get_main_image_url(article['link'])
        featured_id = 0
        uploaded_img_url = ""
        
        if img_url:
            local_img = self.download_image(img_url)
            if local_img:
                media_info = self.upload_media(local_img)
                if media_info:
                    featured_id = media_info['id']
                    uploaded_img_url = media_info['source_url']
                    
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try: 
                    local_img.unlink()
                except: 
                    pass
        else:
            print("   â„¹ï¸  ì´ë¯¸ì§€ ì—†ìŒ")

        # 4. ë³¸ë¬¸ êµ¬ì„± (ì´ë¯¸ì§€ ì‚½ì… + ì›ë³¸ ë§í¬)
        final_content = ""
        
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë³¸ë¬¸ ìµœìƒë‹¨ì— ì‚½ì…
        if uploaded_img_url:
            final_content += f'<figure style="margin: 0 0 30px 0;">'
            final_content += f'<img src="{uploaded_img_url}" alt="{title_ko}" style="width:100%; height:auto; display:block;" />'
            final_content += f'</figure>\n\n'
        
        # ë³¸ë¬¸ ë‚´ìš© (ì¤„ë°”ê¿ˆ HTML ì²˜ë¦¬)
        final_content += content_ko.replace("\n", "<br>\n")
        
        # ì›ë¬¸ ë§í¬ ì¶”ê°€
        final_content += f"\n\n<hr style='margin: 40px 0 20px 0;'>\n"
        final_content += f"<p style='font-size: 14px; color: #666;'>"
        final_content += f"â„¹ï¸ <strong>ì›ë¬¸ ê¸°ì‚¬ ë³´ê¸°:</strong> "
        final_content += f"<a href='{article['link']}' target='_blank' rel='noopener'>{article['title']}</a>"
        final_content += f"</p>"
        
        # 5. ì›Œë“œí”„ë ˆìŠ¤ì— ê²Œì‹œ
        print(f"ğŸ“¤ ì›Œë“œí”„ë ˆìŠ¤ ê²Œì‹œ ì¤‘...")
        if self.post_to_wordpress(title_ko, final_content, featured_id):
            if not FORCE_UPDATE:
                self.posted_articles.append(article['link'])
                self.save_posted_articles()
            return True
        return False

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        print(f"\n{'ğŸš€'*35}")
        print(f"  pronews.jp ìë™ ë²ˆì—­ ì‹œìŠ¤í…œ ì‹œì‘")
        print(f"  ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'ğŸš€'*35}\n")
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        if not WORDPRESS_USER or not WORDPRESS_APP_PASSWORD:
            print("âŒ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í•„ìš”!")
            print("   WP_USERì™€ WP_APP_PASSWORDë¥¼ GitHub Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")
            sys.exit(1)

        # RSS í”¼ë“œì—ì„œ ê¸°ì‚¬ ê°€ì ¸ì˜¤ê¸°
        articles = self.fetch_rss_feed()
        
        if not articles:
            print("â„¹ï¸  ìƒˆë¡œìš´ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê° ê¸°ì‚¬ ì²˜ë¦¬
        success_count = 0
        for article in articles[:10]:  # í•˜ë£¨ ìµœëŒ€ 10ê°œ
            if self.process_article(article):
                success_count += 1
            time.sleep(3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
            
        print(f"\n{'='*70}")
        print(f"ğŸ ì‘ì—… ì™„ë£Œ: {success_count}/{len(articles)}ê°œ ê¸°ì‚¬ ê²Œì‹œë¨")
        print(f"{'='*70}\n")

if __name__ == "__main__":
    bot = NewsTranslator()
    bot.run()
